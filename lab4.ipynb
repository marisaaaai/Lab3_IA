{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f2177e",
   "metadata": {},
   "source": [
    "## Laboratorio 4\n",
    "### Participantes\n",
    "<ul>\n",
    "    <li> Marisa Montoya 19169 </li>\n",
    "    <li> Majo Morales 19145 </li>\n",
    "    <li> Luis Garcia 19344 </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e66ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.18533278,  0.12237949, -0.83328518],\n",
       "        [ 1.42779841, -1.21148644, -0.4613982 ],\n",
       "        [-0.64720576,  0.6277383 ,  0.66474305],\n",
       "        [ 1.68307495,  0.86862674, -0.34625972],\n",
       "        [-1.01010376,  2.39219422, -0.97891845],\n",
       "        [ 1.59054394,  1.64600605, -1.56744637],\n",
       "        [ 0.34614084,  1.36336534,  0.70648817],\n",
       "        [ 1.68493215, -1.33118183, -0.00720934],\n",
       "        [-1.57191719, -0.08428239,  1.04242276],\n",
       "        [ 0.5065725 , -0.5284    , -1.97532062],\n",
       "        [-1.58296149,  1.2064179 ,  1.50693813],\n",
       "        [-2.23081832,  0.36762312,  1.35166138],\n",
       "        [-1.11259108,  1.24920553,  0.18266492],\n",
       "        [-0.85516559,  1.23213627, -0.50132039],\n",
       "        [ 1.00974321,  2.11911058,  0.16441713],\n",
       "        [-1.67956815, -0.81835749, -0.86460777],\n",
       "        [-0.63573684,  1.61405569, -0.28529528],\n",
       "        [ 0.18484653, -1.03141469, -1.81486139],\n",
       "        [-1.50642932,  1.05020194,  0.90977812],\n",
       "        [-0.53385575,  2.02342126, -2.51868754],\n",
       "        [ 0.65260655,  0.56450066, -2.09396983],\n",
       "        [-0.39069935, -1.02291344, -2.24536249],\n",
       "        [-0.55198869,  3.88281659, -4.60709811],\n",
       "        [-1.11771164,  0.08096985, -0.38394089],\n",
       "        [-0.74750188,  1.12750289,  1.85077634],\n",
       "        [ 1.56340526, -1.48027745,  0.06667242],\n",
       "        [-0.89132941,  2.64362856, -1.50364945],\n",
       "        [ 0.58676359, -0.42106708, -2.05577337],\n",
       "        [ 2.8685301 ,  1.4729876 ,  0.07635276],\n",
       "        [ 0.9237696 ,  2.12931439,  0.81798058],\n",
       "        [-0.23484748,  4.27537431, -3.25868138],\n",
       "        [ 0.24549629,  0.3179289 , -0.83219069],\n",
       "        [-1.84017865, -2.23321514,  2.04520519],\n",
       "        [ 1.49198387, -0.99622776, -0.38840148],\n",
       "        [ 0.93145153,  1.80753222, -0.59662946],\n",
       "        [ 1.83734563, -1.6094072 ,  0.34759799],\n",
       "        [ 0.39662038, -1.27000364, -1.30718574],\n",
       "        [ 0.30187502,  0.66869543, -1.77040032],\n",
       "        [-1.64718744,  1.04236333,  1.27694355],\n",
       "        [-0.21091825,  0.77546476,  1.00422419],\n",
       "        [ 1.44066839,  1.29072113, -0.0589414 ],\n",
       "        [-0.97346464,  0.59139125,  1.14176475],\n",
       "        [ 0.54949583, -1.57246659, -0.68814238],\n",
       "        [ 0.86267082, -1.14569361, -0.8403325 ],\n",
       "        [-1.50542704,  0.90203236,  1.76803686],\n",
       "        [-1.37240742, -0.45157921, -0.2153139 ],\n",
       "        [ 1.42452926,  1.14800062,  0.77823036],\n",
       "        [ 0.43979376, -1.78285304, -0.57335322],\n",
       "        [ 0.78103884, -0.13772585, -1.07328642],\n",
       "        [ 2.03169172,  2.6746689 , -0.81946355]]),\n",
       " array([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.make_classification(n_samples=50, n_features=3, n_informative=3, n_redundant=0, n_classes=2)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7cdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0]\n",
    "Y = data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db40131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6537994",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=20, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ab1b215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85516559,  1.23213627, -0.50132039,  0.        ],\n",
       "       [-1.58296149,  1.2064179 ,  1.50693813,  1.        ],\n",
       "       [-0.53385575,  2.02342126, -2.51868754,  0.        ],\n",
       "       [ 0.9237696 ,  2.12931439,  0.81798058,  1.        ],\n",
       "       [ 0.54949583, -1.57246659, -0.68814238,  0.        ],\n",
       "       [-1.37240742, -0.45157921, -0.2153139 ,  0.        ],\n",
       "       [-0.89132941,  2.64362856, -1.50364945,  0.        ],\n",
       "       [-1.84017865, -2.23321514,  2.04520519,  0.        ],\n",
       "       [ 0.18484653, -1.03141469, -1.81486139,  0.        ],\n",
       "       [-1.50542704,  0.90203236,  1.76803686,  1.        ],\n",
       "       [ 0.93145153,  1.80753222, -0.59662946,  1.        ],\n",
       "       [ 1.00974321,  2.11911058,  0.16441713,  1.        ],\n",
       "       [-0.64720576,  0.6277383 ,  0.66474305,  1.        ],\n",
       "       [ 0.86267082, -1.14569361, -0.8403325 ,  0.        ],\n",
       "       [ 1.83734563, -1.6094072 ,  0.34759799,  0.        ],\n",
       "       [-0.39069935, -1.02291344, -2.24536249,  0.        ],\n",
       "       [-1.18533278,  0.12237949, -0.83328518,  0.        ],\n",
       "       [ 1.68307495,  0.86862674, -0.34625972,  1.        ],\n",
       "       [-1.64718744,  1.04236333,  1.27694355,  1.        ],\n",
       "       [ 0.39662038, -1.27000364, -1.30718574,  0.        ],\n",
       "       [ 2.03169172,  2.6746689 , -0.81946355,  1.        ],\n",
       "       [-0.23484748,  4.27537431, -3.25868138,  0.        ],\n",
       "       [-0.21091825,  0.77546476,  1.00422419,  1.        ],\n",
       "       [ 0.5065725 , -0.5284    , -1.97532062,  0.        ],\n",
       "       [-1.57191719, -0.08428239,  1.04242276,  1.        ],\n",
       "       [-1.11771164,  0.08096985, -0.38394089,  0.        ],\n",
       "       [ 1.44066839,  1.29072113, -0.0589414 ,  1.        ],\n",
       "       [ 1.42779841, -1.21148644, -0.4613982 ,  0.        ],\n",
       "       [ 1.59054394,  1.64600605, -1.56744637,  1.        ],\n",
       "       [ 1.42452926,  1.14800062,  0.77823036,  1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.column_stack((X_train,y_train))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5feed4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34614084,  1.36336534,  0.70648817,  1.        ],\n",
       "       [ 0.78103884, -0.13772585, -1.07328642,  1.        ],\n",
       "       [-2.23081832,  0.36762312,  1.35166138,  1.        ],\n",
       "       [-1.01010376,  2.39219422, -0.97891845,  0.        ],\n",
       "       [-1.11259108,  1.24920553,  0.18266492,  1.        ],\n",
       "       [ 0.24549629,  0.3179289 , -0.83219069,  1.        ],\n",
       "       [ 1.68493215, -1.33118183, -0.00720934,  0.        ],\n",
       "       [ 1.56340526, -1.48027745,  0.06667242,  0.        ],\n",
       "       [-0.97346464,  0.59139125,  1.14176475,  1.        ],\n",
       "       [-1.50642932,  1.05020194,  0.90977812,  1.        ],\n",
       "       [-0.55198869,  3.88281659, -4.60709811,  0.        ],\n",
       "       [ 2.8685301 ,  1.4729876 ,  0.07635276,  1.        ],\n",
       "       [ 1.49198387, -0.99622776, -0.38840148,  0.        ],\n",
       "       [-1.67956815, -0.81835749, -0.86460777,  0.        ],\n",
       "       [-0.63573684,  1.61405569, -0.28529528,  0.        ],\n",
       "       [ 0.58676359, -0.42106708, -2.05577337,  0.        ],\n",
       "       [ 0.30187502,  0.66869543, -1.77040032,  1.        ],\n",
       "       [ 0.65260655,  0.56450066, -2.09396983,  1.        ],\n",
       "       [-0.74750188,  1.12750289,  1.85077634,  1.        ],\n",
       "       [ 0.43979376, -1.78285304, -0.57335322,  0.        ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.column_stack((X_test,y_test))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02d79579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "\tnetwork = list()\n",
    "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "\tnetwork.append(hidden_layer)\n",
    "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "\tnetwork.append(output_layer)\n",
    "\treturn network\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4331a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "\tactivation = weights[-1]\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tactivation += weights[i] * inputs[i]\n",
    "\treturn activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcbbc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "\treturn 1.0 / (1.0 + exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d5f6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "\t\tnew_inputs = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "\t\t\tneuron['output'] = transfer(activation)\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\n",
    "\treturn inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e906c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6629970129852887, 0.7253160725279748]\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "\n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "\tactivation = weights[-1]\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tactivation += weights[i] * inputs[i]\n",
    "\treturn activation\n",
    "\n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "\treturn 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "\t\tnew_inputs = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "\t\t\tneuron['output'] = transfer(activation)\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\n",
    "\treturn inputs\n",
    "\n",
    "# test forward propagation\n",
    "network = [[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    "\t\t[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "row = [1, 0, None]\n",
    "output = forward_propagate(network, row)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d063bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "\treturn output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c4a4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "600ee456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\tif i != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17234cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\texpected[row[-1]] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49629672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.500, error=6.350\n",
      ">epoch=1, lrate=0.500, error=5.531\n",
      ">epoch=2, lrate=0.500, error=5.221\n",
      ">epoch=3, lrate=0.500, error=4.951\n",
      ">epoch=4, lrate=0.500, error=4.519\n",
      ">epoch=5, lrate=0.500, error=4.173\n",
      ">epoch=6, lrate=0.500, error=3.835\n",
      ">epoch=7, lrate=0.500, error=3.506\n",
      ">epoch=8, lrate=0.500, error=3.192\n",
      ">epoch=9, lrate=0.500, error=2.898\n",
      ">epoch=10, lrate=0.500, error=2.626\n",
      ">epoch=11, lrate=0.500, error=2.377\n",
      ">epoch=12, lrate=0.500, error=2.153\n",
      ">epoch=13, lrate=0.500, error=1.953\n",
      ">epoch=14, lrate=0.500, error=1.774\n",
      ">epoch=15, lrate=0.500, error=1.614\n",
      ">epoch=16, lrate=0.500, error=1.472\n",
      ">epoch=17, lrate=0.500, error=1.346\n",
      ">epoch=18, lrate=0.500, error=1.233\n",
      ">epoch=19, lrate=0.500, error=1.132\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "\tnetwork = list()\n",
    "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "\tnetwork.append(hidden_layer)\n",
    "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "\tnetwork.append(output_layer)\n",
    "\treturn network\n",
    "\n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "\tactivation = weights[-1]\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tactivation += weights[i] * inputs[i]\n",
    "\treturn activation\n",
    "\n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "\treturn 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "\t\tnew_inputs = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "\t\t\tneuron['output'] = transfer(activation)\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\n",
    "\treturn inputs\n",
    "\n",
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "\treturn output * (1.0 - output)\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\tif i != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']\n",
    "\n",
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\texpected[row[-1]] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\n",
    "# Test training backprop algorithm\n",
    "seed(1)\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "#for layer in network:\n",
    "#\tprint(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1aa18e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=1, Got=0\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=1, Got=0\n",
      "Expected=1, Got=0\n",
      "Expected=0, Got=1\n",
      "Expected=0, Got=1\n",
      "Expected=1, Got=0\n",
      "Expected=1, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=1, Got=1\n",
      "Expected=0, Got=1\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=1\n",
      "Expected=1, Got=0\n",
      "Expected=1, Got=0\n",
      "Expected=1, Got=0\n",
      "Expected=0, Got=1\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "\n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "\tactivation = weights[-1]\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tactivation += weights[i] * inputs[i]\n",
    "\treturn activation\n",
    "\n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "\treturn 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "\t\tnew_inputs = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "\t\t\tneuron['output'] = transfer(activation)\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\n",
    "\treturn inputs\n",
    "\n",
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "\toutputs = forward_propagate(network, row)\n",
    "\treturn outputs.index(max(outputs))\n",
    "\n",
    "# Test making predictions with the network\n",
    "dataset = test\n",
    "network = [[{'weights': [-1.482313569067226, 1.8308790073202204, 1.078381922048799]}, {'weights': [0.23244990332399884, 0.3621998343835864, 0.40289821191094327]}],\n",
    "\t[{'weights': [2.5001872433501404, 0.7887233511355132, -1.1026649757805829]}, {'weights': [-2.429350576245497, 0.8357651039198697, 1.0699217181280656]}]]\n",
    "predictions = []\n",
    "for row in dataset:\n",
    "\tprediction = predict(network, row)\n",
    "\tpredictions.append(prediction)\n",
    "\tprint('Expected=%d, Got=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8de39662",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "for i in range(len(y_test)):\n",
    "    real.append(y_test[i])\n",
    "count = 0 \n",
    "for i in range(len(real)):\n",
    "    if (real[i]==predictions[i]):\n",
    "        count = count + 1\n",
    "ac\n",
    "print ('accuracy score',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
